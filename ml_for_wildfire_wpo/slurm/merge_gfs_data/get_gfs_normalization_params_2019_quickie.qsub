#!/bin/tcsh

#SBATCH --job-name="get_gfs_normalization_params_2019_quickie"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=04:00:00
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=get_gfs_normalization_params_2019_quickie_%A.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_standalone/ml_for_wildfire_wpo"
set INPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed/merged"
set OUTPUT_FILE_NAME="${INPUT_DIR_NAME}/z_score_params_2019_quickie.nc"

python3 -u "${CODE_DIR_NAME}/get_z_score_params_for_gfs.py" \
--input_gfs_dir_name="${INPUT_DIR_NAME}" \
--first_init_date_strings "20190101" "20190202" "20190303" "20190404" "20190505" "20190606" "20190707" "20190808" "20190909" "20191010" "20191111" "20191212" \
--last_init_date_strings "20190101" "20190202" "20190303" "20190404" "20190505" "20190606" "20190707" "20190808" "20190909" "20191010" "20191111" "20191212" \
--output_norm_file_name="${OUTPUT_FILE_NAME}"
