#!/bin/bash

#SBATCH --job-name="apply_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="gpuwf"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=01:30:00
#SBATCH --array=1-120
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=apply_neural_nets_%A_%a.out

module load cuda/12.1.0
conda init
conda activate base

echo `which conda`
echo `which python`
echo `which python3`

# PATH=/usr/local/cuda/bin:$PATH
echo $PATH

CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_standalone/ml_for_wildfire_wpo"
TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_models/experiment06_grad_accum_2var"

GFS_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed/quantile_normalized_params_from_2019-2020"
TARGET_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/canadian_fwi"
GFS_FORECAST_TARGET_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed_fwi_forecasts"

BATCH_SIZES=("08" "08" "08" "08" "08" "16" "16" "16" "16" "16" "24" "24" "24" "24" "24" "32" "32" "32" "32" "32" "08" "08" "08" "08" "08" "16" "16" "16" "16" "16" "24" "24" "24" "24" "24" "32" "32" "32" "32" "32" "08" "08" "08" "08" "08" "16" "16" "16" "16" "16" "24" "24" "24" "24" "24" "32" "32" "32" "32" "32" "08" "08" "08" "08" "08" "16" "16" "16" "16" "16" "24" "24" "24" "24" "24" "32" "32" "32" "32" "32" "08" "08" "08" "08" "08" "16" "16" "16" "16" "16" "24" "24" "24" "24" "24" "32" "32" "32" "32" "32" "08" "08" "08" "08" "08" "16" "16" "16" "16" "16" "24" "24" "24" "24" "24" "32" "32" "32" "32" "32")
DROPOUT_LAYER_COUNTS=("1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "1" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "2" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "3" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "4" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "5" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6" "6")
DROPOUT_RATES=("0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5" "0.1" "0.2" "0.3" "0.4" "0.5")

batch_size=${BATCH_SIZES[$SLURM_ARRAY_TASK_ID]}
num_dropout_layers=${DROPOUT_LAYER_COUNTS[$SLURM_ARRAY_TASK_ID]}
dropout_rate=${DROPOUT_RATES[$SLURM_ARRAY_TASK_ID]}

model_dir_name="${TOP_MODEL_DIR_NAME}/batch-size=${batch_size}_num-dropout-layers=${num_dropout_layers}_dropout-rate=${dropout_rate}"
echo $model_dir_name

python3 -u "${CODE_DIR_NAME}/apply_neural_net.py" \
--input_model_file_name="${model_dir_name}/model.keras" \
--input_gfs_directory_name="${GFS_DIR_NAME}" \
--input_target_dir_name="${TARGET_DIR_NAME}" \
--input_gfs_fcst_target_dir_name="${GFS_FORECAST_TARGET_DIR_NAME}" \
--init_date_limit_strings "20210101" "20211210" \
--output_dir_name="${model_dir_name}/validation"
