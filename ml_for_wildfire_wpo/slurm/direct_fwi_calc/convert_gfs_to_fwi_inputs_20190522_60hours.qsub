#!/bin/tcsh

#SBATCH --job-name="convert_gfs_to_fwi_inputs_20190522_60hours"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=03:30:00
#SBATCH --array=1
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=convert_gfs_to_fwi_inputs_20190522_60hours_%A_%a.out

module load cuda/10.1
module load gnu/9.2.0
module load wgrib2/3.1.1_ncep

source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_standalone/ml_for_wildfire_wpo"
set INPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/direct_fwi_calc/processed"
set OUTPUT_DIR_NAME="${INPUT_DIR_NAME}/daily"

set INIT_DATE_STRINGS=("20190522")
set i=$SLURM_ARRAY_TASK_ID

while ($i <= `expr $SLURM_ARRAY_TASK_ID + 11` && $i <= $#INIT_DATE_STRINGS)
    set init_date_string="${INIT_DATE_STRINGS[$i]}"
    
    python3 -u "${CODE_DIR_NAME}/convert_gfs_to_daily_fwi_inputs.py" \
    --input_gfs_dir_name="${INPUT_DIR_NAME}" \
    --first_init_date_string="${init_date_string}" \
    --last_init_date_string="${init_date_string}" \
    --max_lead_time_days=2 \
    --output_daily_gfs_dir_name="${OUTPUT_DIR_NAME}"
    
    @ i = $i + 1
end
