#!/bin/bash

#SBATCH --job-name="apply_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="gpuwf"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=24:00:00
#SBATCH --array=0-55
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=apply_neural_nets_%A_%a.out

module load cuda/12.3.1
conda init
conda activate base

echo `which conda`
echo `which python`
echo `which python3`

# PATH=/usr/local/cuda/bin:$PATH
echo $PATH

CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_standalone/ml_for_wildfire_wpo"
TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_models/experiment21_convnext"

GFS_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed/quantile_normalized_params_from_2019-2020"
TARGET_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/canadian_fwi"
GFS_FORECAST_TARGET_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed_fwi_forecasts"

TRAINING_STRATEGIES=("20-50-diff-plus2days" "20-50-diff-plus2days" "40-10-diff" "40-10-diff" "20-30-daily" "20-30-daily" "80-40-diff-plus2days" "80-40-diff-plus2days" "20-50-diff-plus2days" "20-50-diff-plus2days" "40-10-diff" "40-10-diff" "20-30-daily" "20-30-daily" "80-40-diff-plus2days" "80-40-diff-plus2days" "20-50-diff-plus2days" "20-50-diff-plus2days" "40-10-diff" "40-10-diff" "20-30-daily" "20-30-daily" "80-40-diff-plus2days" "80-40-diff-plus2days" "20-50-diff-plus2days" "20-50-diff-plus2days" "40-10-diff" "40-10-diff" "20-30-daily" "20-30-daily" "80-40-diff-plus2days" "80-40-diff-plus2days" "20-50-diff-plus2days" "20-50-diff-plus2days" "40-10-diff" "40-10-diff" "20-30-daily" "20-30-daily" "80-40-diff-plus2days" "80-40-diff-plus2days" "20-50-diff-plus2days" "20-50-diff-plus2days" "40-10-diff" "40-10-diff" "20-30-daily" "20-30-daily" "80-40-diff-plus2days" "80-40-diff-plus2days" "20-50-diff-plus2days" "20-50-diff-plus2days" "40-10-diff" "40-10-diff" "20-30-daily" "20-30-daily" "80-40-diff-plus2days" "80-40-diff-plus2days")
SPECTRAL_COMPLEXITIES=("010" "010" "010" "010" "010" "010" "010" "010" "015" "015" "015" "015" "015" "015" "015" "015" "020" "020" "020" "020" "020" "020" "020" "020" "025" "025" "025" "025" "025" "025" "025" "025" "030" "030" "030" "030" "030" "030" "030" "030" "035" "035" "035" "035" "035" "035" "035" "035" "040" "040" "040" "040" "040" "040" "040" "040")
USE_LEAD_TIME_AS_PRED_FLAGS=("0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1" "0" "1")

training_strategy=${TRAINING_STRATEGIES[$SLURM_ARRAY_TASK_ID]}
spectral_complexity=${SPECTRAL_COMPLEXITIES[$SLURM_ARRAY_TASK_ID]}
use_lead_time_as_predictor=${USE_LEAD_TIME_AS_PRED_FLAGS[$SLURM_ARRAY_TASK_ID]}

model_dir_name="${TOP_MODEL_DIR_NAME}/training-strategy=${training_strategy}_spectral-complexity=${spectral_complexity}_use-lead-time-as-predictor=${use_lead_time_as_predictor}"
echo $model_dir_name

MODEL_LEAD_TIMES_DAYS=("01" "02" "03" "04" "05" "06" "07" "08" "09" "10" "11" "12" "13" "14")

for model_lead_time_days in "${MODEL_LEAD_TIMES_DAYS[@]}"; do
    python3 -u "${CODE_DIR_NAME}/apply_neural_net.py" \
    --input_model_file_name="${model_dir_name}/model.weights.h5" \
    --input_gfs_directory_name="${GFS_DIR_NAME}" \
    --input_target_dir_name="${TARGET_DIR_NAME}" \
    --input_gfs_fcst_target_dir_name="${GFS_FORECAST_TARGET_DIR_NAME}" \
    --init_date_limit_strings "20210101" "20211210" \
    --model_lead_time_days=${model_lead_time_days} \
    --take_ensemble_mean=1 \
    --output_dir_name="${model_dir_name}/validation_lead-time-days=${model_lead_time_days}"
done
