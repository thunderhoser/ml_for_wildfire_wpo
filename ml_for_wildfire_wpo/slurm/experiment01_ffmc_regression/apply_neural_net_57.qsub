#!/bin/tcsh

#SBATCH --job-name="apply_neural_net_57"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="batch"
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --cpus-per-task=1
##SBATCH --nodes=1
##SBATCH --ntasks=1
##SBATCH --cpus-per-task=1
##SBATCH --ntasks-per-node=1
#SBATCH --time=02:00:00
#SBATCH --array=57
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=apply_neural_net_57_%A_%a.out

module load cuda/10.1
source /scratch2/BMC/gsd-hpcs/Jebb.Q.Stewart/conda3.7/etc/profile.d/conda.csh
conda activate base

set CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_standalone/ml_for_wildfire_wpo"
set TOP_MODEL_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_models/experiment01_ffmc_regression"

set GFS_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed/merged/normalized_params_from_2019-2020"
set TARGET_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/canadian_fwi"

set LAYERS_PER_BLOCK_COUNTS=("1" "1" "1" "1" "1" "1" "1" "1" "1" "2" "2" "2" "2" "2" "2" "2" "2" "2" "1" "1" "1" "1" "1" "1" "1" "1" "1" "2" "2" "2" "2" "2" "2" "2" "2" "2" "1" "1" "1" "1" "1" "1" "1" "1" "1" "2" "2" "2" "2" "2" "2" "2" "2" "2" "1" "1" "1" "1" "1" "1" "1" "1" "1" "2" "2" "2" "2" "2" "2" "2" "2" "2" "1" "1" "1" "1" "1" "1" "1" "1" "1" "2" "2" "2" "2" "2" "2" "2" "2" "2")
set FIRST_LAYER_FILTER_COUNTS=("10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "10" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "15" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "20" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "25" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30" "30")
set GFS_LEAD_TIME_STRINGS=("0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72" "0-48" "0-24-48" "0-24-48-72" "0-18-36-48" "0-12-24-36-48" "0-18-36-48-60-72" "0-12-24-36-48-60-72" "0-6-12-18-24-30-36-42-48" "0-6-12-18-24-30-36-42-48-60-72")

set BEST_MODEL_INDEX=57

set num_layers_per_block=${LAYERS_PER_BLOCK_COUNTS[$BEST_MODEL_INDEX]}
set num_first_layer_filters=${FIRST_LAYER_FILTER_COUNTS[$BEST_MODEL_INDEX]}
set gfs_lead_time_string=${GFS_LEAD_TIME_STRINGS[$BEST_MODEL_INDEX]}

set model_dir_name="${TOP_MODEL_DIR_NAME}/num-conv-layers-per-block=${num_layers_per_block}_num-first-layer-filters=${num_first_layer_filters}_gfs-lead-times-hours=${gfs_lead_time_string}"
echo $model_dir_name

set FIRST_DATE_STRINGS=("20210101" "20210109" "20210117" "20210125" "20210202" "20210210" "20210218" "20210226" "20210306" "20210314" "20210322" "20210330" "20210407" "20210415" "20210423" "20210501" "20210509" "20210517" "20210525" "20210602" "20210610" "20210618" "20210626" "20210704" "20210712" "20210720" "20210728" "20210805" "20210813" "20210821" "20210829" "20210906" "20210914" "20210922" "20210930" "20211008" "20211016" "20211024" "20211101" "20211109" "20211117" "20211125" "20211203")
set LAST_DATE_STRINGS=("20210108" "20210116" "20210124" "20210201" "20210209" "20210217" "20210225" "20210305" "20210313" "20210321" "20210329" "20210406" "20210414" "20210422" "20210430" "20210508" "20210516" "20210524" "20210601" "20210609" "20210617" "20210625" "20210703" "20210711" "20210719" "20210727" "20210804" "20210812" "20210820" "20210828" "20210905" "20210913" "20210921" "20210929" "20211007" "20211015" "20211023" "20211031" "20211108" "20211116" "20211124" "20211202" "20211210")

python3 -u "${CODE_DIR_NAME}/apply_neural_net.py" \
--input_model_file_name="${model_dir_name}/model.h5" \
--input_gfs_directory_name="${GFS_DIR_NAME}" \
--input_target_dir_name="${TARGET_DIR_NAME}" \
--init_date_limit_strings "${FIRST_DATE_STRINGS[$SLURM_ARRAY_TASK_ID]}" "${LAST_DATE_STRINGS[$SLURM_ARRAY_TASK_ID]}" \
--output_dir_name="${model_dir_name}/validation"
