#!/bin/bash

#SBATCH --job-name="train_neural_nets"
#SBATCH --partition="fge"
#SBATCH --account="rda-ghpcs"
#SBATCH --qos="gpuwf"
#SBATCH --nodes=1
#SBATCH --ntasks=8           # 8 tasks per node
#SBATCH --cpus-per-task=2
#SBATCH --ntasks-per-node=8  # 8 GPUs per node
#SBATCH --exclusive
#SBATCH --time=168:00:00
#SBATCH --array=0-11
#SBATCH --exclude=h28n12
##SBATCH --exclude=h31n03,h28n12
##SBATCH --exclude=h29n01,h26n05,h28n06,h29n07,h30n03,h30n15
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ryan.lagerquist@noaa.gov
#SBATCH --output=train_neural_nets_%A_%a.out

module load cuda/12.3.1
conda init
conda activate base

echo `which conda`
echo `which python`
echo `which python3`

# PATH=/usr/local/cuda/bin:$PATH
echo $PATH

CODE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_standalone/ml_for_wildfire_wpo"
TEMPLATE_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_models/experiment23a_ablation/templates"
TOP_OUTPUT_DIR_NAME="/scratch1/RDARCH/rda-ghpcs/Ryan.Lagerquist/ml_for_wildfire_models/experiment23a_ablation"

GFS_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed/quantile_normalized_params_from_2019-2020"
TARGET_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/canadian_fwi"
GFS_FORECAST_TARGET_DIR_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/gfs_data/processed_fwi_forecasts"
TARGET_NORM_FILE_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/canadian_fwi/normalization_params_2019-2020.nc"
ERA5_CONSTANT_FILE_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/era5_constants.nc"
# ERA5_CONSTANT_NORM_FILE_NAME="/scratch2/BMC/gsd-hpcs/Ryan.Lagerquist/ml_for_wildfire_wpo_project/normalization_params_era5_constants.nc"

PREDICTOR_TYPE_STRINGS=("gfs_surface" "gfs_1000mb" "gfs_900mb" "gfs_800mb" "gfs_700mb" "gfs_600mb" "gfs_500mb" "gfs_400mb" "gfs_300mb" "gfs_200mb" "lagged_targets" "gfs_forecast_targets")
predictor_type_string=${PREDICTOR_TYPE_STRINGS[$SLURM_ARRAY_TASK_ID]}

gfs_pred_leads_hours_by_model_lead="24 -1 48 -1 72 -1 96 -1 120 -1 144 -1 168 -1 192 -1 216 -1 240 -1 264 -1 288 -1 312 -1 336"

second_lead_time_start_epoch=40
num_rampup_epochs=10

if [[ "$predictor_type_string" = "gfs_surface" ]]; then
    template_file_name="${TEMPLATE_DIR_NAME}/predictor_type=gfs_2d/model.keras"
    gfs_predictor_field_names="temperature_2m_agl_kelvins specific_humidity_2m_agl_kg_kg01 u_wind_10m_agl_m_s01 v_wind_10m_agl_m_s01 accumulated_precip_metres"
    gfs_pressure_levels_mb="-1"
    target_lags_days_by_model_lead="-1"
    gfs_target_leads_days_by_model_lead="-1"
elif [[ "$predictor_type_string" == gfs_*mb ]]; then
    template_file_name="${TEMPLATE_DIR_NAME}/predictor_type=gfs_3d/model.keras"
    gfs_predictor_field_names="temperature_kelvins specific_humidity_kg_kg01 geopotential_height_m_asl u_wind_m_s01 v_wind_m_s01"
    target_lags_days_by_model_lead="-1"
    gfs_target_leads_days_by_model_lead="-1"
    gfs_pressure_levels_mb=${predictor_type_string#gfs_}
    gfs_pressure_levels_mb=${gfs_pressure_levels_mb%mb}
elif [[ "$predictor_type_string" = "lagged_targets" ]]; then
    template_file_name="${TEMPLATE_DIR_NAME}/predictor_type=lagged_targets/model.keras"
    gfs_predictor_field_names="None"
    gfs_pressure_levels_mb="-1"
    target_lags_days_by_model_lead="1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1 -1 1"
    gfs_target_leads_days_by_model_lead="-1"
else
    template_file_name="${TEMPLATE_DIR_NAME}/predictor_type=gfs_forecast_targets/model.keras"
    gfs_predictor_field_names="None"
    gfs_pressure_levels_mb="-1"
    target_lags_days_by_model_lead="-1"
    gfs_target_leads_days_by_model_lead="1 -1 2 -1 3 -1 4 -1 5 -1 6 -1 7 -1 8 -1 9 -1 10 -1 11 -1 12 -1 13 -1 14"
fi

output_dir_name="${TOP_OUTPUT_DIR_NAME}/predictor_type=${predictor_type_string}"
echo $output_dir_name

while true; do
    python3 -u "${CODE_DIR_NAME}/train_neural_net.py" \
    --input_template_file_name="${template_file_name}" \
    --output_model_dir_name="${output_dir_name}" \
    --inner_latitude_limits_deg_n 17 73 \
    --inner_longitude_limits_deg_e 171 -65 \
    --outer_latitude_buffer_deg=5 \
    --outer_longitude_buffer_deg=5 \
    --gfs_predictor_field_names ${gfs_predictor_field_names} \
    --gfs_pressure_levels_mb ${gfs_pressure_levels_mb} \
    --model_lead_times_days 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \
    --curriculum_start_epoch_by_model_lead 0 ${second_lead_time_start_epoch} $((second_lead_time_start_epoch + num_rampup_epochs)) $((second_lead_time_start_epoch + 2 * num_rampup_epochs)) $((second_lead_time_start_epoch + 3 * num_rampup_epochs)) $((second_lead_time_start_epoch + 4 * num_rampup_epochs)) $((second_lead_time_start_epoch + 5 * num_rampup_epochs)) $((second_lead_time_start_epoch + 6 * num_rampup_epochs)) $((second_lead_time_start_epoch + 7 * num_rampup_epochs)) $((second_lead_time_start_epoch + 8 * num_rampup_epochs)) $((second_lead_time_start_epoch + 9 * num_rampup_epochs)) $((second_lead_time_start_epoch + 10 * num_rampup_epochs)) $((second_lead_time_start_epoch + 11 * num_rampup_epochs)) $((second_lead_time_start_epoch + 12 * num_rampup_epochs)) \
    --curriculum_num_rampup_epochs=${num_rampup_epochs} \
    --gfs_pred_leads_hours_by_model_lead ${gfs_pred_leads_hours_by_model_lead} \
    --gfs_normalization_file_name="" \
    --era5_constant_file_name="${ERA5_CONSTANT_FILE_NAME}" \
    --era5_normalization_file_name="" \
    --era5_use_quantile_norm=0 \
    --target_field_names "fine_fuel_moisture_code" "duff_moisture_code" "drought_code" "initial_spread_index" "buildup_index" "fire_weather_index" "daily_severity_rating" \
    --target_lags_days_by_model_lead ${target_lags_days_by_model_lead} \
    --gfs_target_leads_days_by_model_lead ${gfs_target_leads_days_by_model_lead} \
    --compare_to_gfs_in_loss=1 \
    --target_normalization_file_name="${TARGET_NORM_FILE_NAME}" \
    --targets_use_quantile_norm=1 \
    --num_examples_per_batch=1 \
    --sentinel_value=-10 \
    --do_residual_prediction=0 \
    --use_lead_time_as_predictor=1 \
    --change_model_lead_every_n_batches=-1 \
    --outer_patch_size_deg=40 \
    --outer_patch_overlap_size_deg=15 \
    --gfs_dir_name_for_training="${GFS_DIR_NAME}" \
    --target_dir_name_for_training="${TARGET_DIR_NAME}" \
    --gfs_forecast_target_dir_name_for_training="${GFS_FORECAST_TARGET_DIR_NAME}" \
    --gfs_init_date_limit_strings_for_training "20190101" "20201210" \
    --gfs_dir_name_for_validation="${GFS_DIR_NAME}" \
    --target_dir_name_for_validation="${TARGET_DIR_NAME}" \
    --gfs_forecast_target_dir_name_for_validation="${GFS_FORECAST_TARGET_DIR_NAME}" \
    --gfs_init_date_limit_strings_for_validation "20210101" "20211210" \
    --num_epochs=600 \
    --num_training_batches_per_epoch=704 \
    --num_validation_batches_per_epoch=264 \
    --plateau_patience_epochs=${num_rampup_epochs} \
    --plateau_learning_rate_multiplier=0.95 \
    --early_stopping_patience_epochs=10000
done
